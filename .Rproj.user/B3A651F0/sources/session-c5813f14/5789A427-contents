library(dplyr)
library(tidyr)        # bind_cols()
library(caret)        # train(), preProcess()
library(rpart)        # CART backend
library(randomForest) # Random Forest
library(xgboost)      # XGBoost
library(gbm)
library(stargazer)    # summary tables
library(tibble)       # tibble support
library(Metrics)
library(ggplot2)
library(knitr)
library(tidyr)
library(dplyr)

dir.create(file.path("./assignment3/tables"), recursive = TRUE, showWarnings = FALSE)
dir.create(file.path("./assignment3/figures"), recursive = TRUE, showWarnings = FALSE)
dir.create(file.path("./assignment3/data"), recursive = TRUE, showWarnings = FALSE)

source("scripts/helpers.R") # contains the function summarize_feature_importance_trees()

# ---
# Constants
# ---
CART_CP <- 0.001

MTRY_RF <- 24
NTREE_RF <- 200

NROUNDS_XG <- 100
MAX_DEPTH_XG <- 7
ETA_XG <- 0.1
COLSAMPLE_XG <- 1
MIN_CHILD_WEIGHT_XG <- 1
SUBSAMPLE_XG <- 0.7


# Load the two datasets ----

train_path <- "./assignment3/data/trainDataset_clean.csv"
test_path  <- "./assignment3/data/testDataset_clean.csv"

# Read the CSV files
train <- read.csv(train_path, stringsAsFactors = FALSE)
train <- train[complete.cases(train), ]

test  <- read.csv(test_path,  stringsAsFactors = FALSE)

# Question 1 ----
### Add congestion dummy and save datasets.
### Congestion = 1 if speed_main < 106, else 0

q25 <-  104 

cat("25th percentile (train speed_main):", q25, "\n")

# Create cogestion dummy in train and test
train$congestion <- ifelse(train$speed_main < q25, 1, 0)
test$congestion <- ifelse(test$speed_main < q25, 1, 0)

#Save the updated datasets
write.csv(train, "./assignment3/data/train_with_congestion.csv", row.names = FALSE)
write.csv(test, "./assignment3/data/test_with_congestion.csv", row.names = FALSE)

# Question 2 ----
### Train parameters using Logit, Cart, RF, Gradient Boosting using train set
### Compute and report the variable importance

# Choose which columns to use as predictors
# Remove the target (congestion) and speed_main (based on target)
predictor_cols <- setdiff(names(train), c("congestion", "speed_main", "speed_ngh_432"))

# Build a formula
model_formula <- as.formula(
  paste("congestion~", paste(predictor_cols, collapse = "+"))
)

cat("Model formula:\n")
print(model_formula)

## (1) LOGIT Model ----

logit_model <- glm(model_formula, data = train, family = binomial(link = "logit"))

## (2) CART Model ----

cart_model <- rpart(model_formula, data=train, method="class",
                    control = rpart.control(cp = CART_CP))

## (3) Random Forest Model ----

# Keep the assignment constant, but make sure it is in a valid range (no warning)
mtry_used <- max(1, min(MTRY_RF, length(predictor_cols)))

set.seed(123)  # for reproducibility
rf_model <- randomForest(
  x = train[, predictor_cols],
  y = as.factor(train$congestion),
  mtry = mtry_used,
  ntree = NTREE_RF,
  importance = TRUE
)

## (4) Gradient Boosting Model ----
# Replaced by XGBoost (new one)

set.seed(123)

train_matrix <- as.matrix(train[, predictor_cols])
train_label  <- train$congestion
test_matrix  <- as.matrix(test[, predictor_cols])

dtrain <- xgb.DMatrix(data = train_matrix, label = train_label)

params <- list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  max_depth = MAX_DEPTH_XG,
  learning_rate = ETA_XG,
  colsample_bytree = COLSAMPLE_XG,
  min_child_weight = MIN_CHILD_WEIGHT_XG,
  subsample = SUBSAMPLE_XG
)

xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = NROUNDS_XG,
  verbose = 0
)

# Variable importance (trees) ----
# Uses helpers.R and saves to ./tables/feature_importance_trees.{txt,tex,html}

summarize_feature_importance_trees(
  models = list(cart_model, rf_model, xgb_model),
  model_names = c("CART", "Random Forest", "XGBoost"),
  output_prefix = "./assignment3/tables/feature_importance_trees"
)

# Question 3 ----
# Predict congestion on test set and create confusion matrices

# Helper: confusion matrix + simple metrics
make_confusion <- function(y_true, y_pred) {
  # Force to 0/1
  y_true <- as.integer(y_true)
  y_pred <- as.integer(y_pred)
  
  # Confusion matrix in the standard layout:
  #           Pred 0   Pred 1
  # True 0      TN       FP
  # True 1      FN       TP
  cm <- table(
    "True" = factor(y_true, levels = c(0, 1)),
    "Pred" = factor(y_pred, levels = c(0, 1))
  )
  
  TN <- cm["0", "0"]
  FP <- cm["0", "1"]
  FN <- cm["1", "0"]
  TP <- cm["1", "1"]
  
  accuracy  <- (TP + TN) / (TP + TN + FP + FN)
  precision <- ifelse((TP + FP) == 0, NA, TP / (TP + FP))
  recall    <- ifelse((TP + FN) == 0, NA, TP / (TP + FN))
  f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
                      NA, 2 * precision * recall / (precision + recall))
  
  list(cm = cm,
       metrics = c(Accuracy = accuracy, Precision = precision, Recall = recall, F1 = f1))
}

# Helper: save a LaTeX table for the confusion matrix
save_cm_latex <- function(cm, model_name, file_path) {
  cm_df <- as.data.frame.matrix(cm)
  cm_df <- data.frame(True = rownames(cm_df), cm_df, row.names = NULL)
  
  latex_code <- kable(
    cm_df,
    format = "latex",
    booktabs = TRUE,
    caption = paste("Confusion matrix on test set -", model_name),
    label = paste0("tab:cm_", gsub(" ", "_", tolower(model_name)))
  )
  
  writeLines(latex_code, file_path)
  cat("✅ Saved:", file_path, "\n")
}

## (1) Logit Predictions ----
p_logit <- predict(logit_model, newdata = test, type = "response")
pred_logit <- ifelse(p_logit >= 0.5, 1, 0)

res_logit <- make_confusion(test$congestion, pred_logit)
save_cm_latex(res_logit$cm, "Logit", "./assignment3/tables/cm_logit.tex")

## (2) CART predictions ----
pred_cart <- predict(cart_model, newdata = test, type = "class")
pred_cart <- as.integer(as.character(pred_cart))  # factors "0"/"1" -> 0/1

res_cart <- make_confusion(test$congestion, pred_cart)
save_cm_latex(res_cart$cm, "CART", "./assignment3/tables/cm_cart.tex")

## (3) Random Forest predictions ----
pred_rf <- predict(rf_model, newdata = test[, predictor_cols], type = "class")
pred_rf <- as.integer(as.character(pred_rf))

res_rf <- make_confusion(test$congestion, pred_rf)
save_cm_latex(res_rf$cm, "Random Forest", "./assignment3/tables/cm_random_forest.tex")

## (4) Gradient Boosting predictions ----
# Replaced by XGBoost (new one)

p_xgb <- predict(xgb_model, newdata = test_matrix)
pred_xgb <- ifelse(p_xgb >= 0.5, 1, 0)

res_xgb <- make_confusion(test$congestion, pred_xgb)
save_cm_latex(res_xgb$cm, "XGBoost", "./assignment3/tables/cm_xgb.tex")

# Question 4 ----
# Compute Precision, Recall, Accuracy, F1 scores for the four models

metrics_table <- data.frame(
  Model = c("Logit", "CART", "Random Forest", "XGBoost"),
  rbind(res_logit$metrics, res_cart$metrics, res_rf$metrics, res_xgb$metrics),
  row.names = NULL
)

# Round for readability
metrics_table[, -1] <- round(metrics_table[, -1], 3)

metrics_latex <- kable(
  metrics_table,
  format = "latex",
  booktabs = TRUE,
  caption = "Test-set performance summary (threshold = 0.5).",
  label = "tab:test_metrics"
)
writeLines(metrics_latex, "./assignment3/tables/test_metrics_summary.tex")

# Question 5 ----
# Analysis of congestion by hour and by week for GT and four predictions

# Put predictions in the test data
test$pred_logit <- pred_logit
test$pred_cart  <- pred_cart
test$pred_rf    <- pred_rf
test$pred_xgb   <- pred_xgb



# Helper to compute congestion rates by group
# Returns % congested (= mean of 0/1) for each group and each column
rate_by_group <- function(data, group_col, cols_to_summarize) {
  out <- aggregate(
    x = data[, cols_to_summarize],
    by = list(group = data[[group_col]]),
    FUN = mean
  )
  names(out)[1] <- group_col
  out
}

# Columns we want to summarize
cols <- c("congestion", "pred_logit", "pred_cart", "pred_rf", "pred_xgb")

## By Hour ----
# Create an "hour" variable from hour7/hour8/hour9
test$hour <- ifelse(test$hour6 == 1, 6,
                    ifelse(test$hour7 == 1, 7,
                                      ifelse(test$hour8 == 1, 8,
                                             ifelse(test$hour9 == 1, 9, "other"))))

hour_table <- rate_by_group(test, "hour", cols)

# Convert rates to percentages for readability
hour_table[cols] <- lapply(hour_table[cols], function(x) round(x, 1))

# Create LaTex Table
hour_tex <- kable(
  hour_table,
  format = "latex",
  booktabs = TRUE,
  caption = "Congestion rate by hour on the test set (percent congested).",
  label = "tab:cong_by_hour"
)
writeLines(hour_tex, "./assignment3/tables/congestion_by_hour.tex")


## By Week ----
week_table <- rate_by_group(test, "week", cols)

# Sort by week
week_table <- week_table[order(week_table$week), ]

# Convert to percentages
week_table[cols] <- lapply(week_table[cols], function(x) round(x * 100, 1))

week_tex <- kable(
  week_table,
  format = "latex",
  booktabs = TRUE,
  caption = "Congestion rate by week on the test set (percent congested).",
  label = "tab:cong_by_week"
)
writeLines(week_tex, "./assignment3/tables/congestion_by_week.tex")

## Plots ----
# Convert to "long" format for ggplot
hour_long <- hour_table %>%
  pivot_longer(cols = all_of(cols), names_to = "series", values_to = "rate")

week_long <- week_table %>%
  pivot_longer(cols = all_of(cols), names_to = "series", values_to = "rate")

# Friendly labels
series_labels <- c(
  congestion = "Truth",
  pred_logit = "Logit",
  pred_cart  = "CART",
  pred_rf    = "Random Forest",
  pred_xgb   = "XGBoost"
)

#Plot: Congestion by HOUR (bar chart)
p_hour <- ggplot(hour_long, aes(x = hour, y = rate * 100, fill = series)) +
  geom_col(position = position_dodge(width = 0.85), width = 0.8, color = "grey30") +
  scale_fill_discrete(labels = series_labels) +
  labs(
    x = "Hour",
    y = "Congestion rate (%)",
    fill = ""
  ) +
  theme_bw(base_family = "serif") +
  theme(
    panel.grid.major = element_line(linewidth = 0.35),
    panel.grid.minor = element_line(linewidth = 0.2),
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )

ggsave("./assignment3/figures/congestion_by_hour.pdf", p_hour, width = 9, height = 5, dpi = 300)

#Plot: Congestion by WEEK (line chart)
p_week <- ggplot(week_long, aes(x = week, y = rate, linetype = series, shape = series)) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 2) +
  scale_linetype_discrete(labels = series_labels) +
  scale_shape_discrete(labels = series_labels) +
  labs(
    x = "Week",
    y = "Congestion rate (%)",
    linetype = "",
    shape = ""
  ) +
  theme_bw(base_family = "serif") +
  theme(
    panel.grid.major = element_line(linewidth = 0.35),
    panel.grid.minor = element_line(linewidth = 0.2),
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )

ggsave("./assignment3/figures/congestion_by_week.pdf", p_week, width = 10, height = 5.5, dpi = 300)

## Absolute Error by Week ----
# Prediction columns only (exclude truth)
pred_cols <- c("pred_logit", "pred_cart", "pred_rf", "pred_xgb")

# week_table currently stores percentages (because you multiplied by 100 earlier).
# Convert back to rates (0-1) so the math is correct:
week_rates <- week_table %>%
  mutate(
    truth = congestion / 100,
    pred_logit = pred_logit / 100,
    pred_cart  = pred_cart  / 100,
    pred_rf    = pred_rf    / 100,
    pred_xgb   = pred_xgb   / 100
  ) %>%
  select(week, truth, all_of(pred_cols))

# Long format: one row per (week, model)
week_abs_err <- week_rates %>%
  pivot_longer(cols = all_of(pred_cols), names_to = "model", values_to = "pred_rate") %>%
  mutate(
    abs_error = abs(pred_rate - truth),
    model = factor(model, levels = names(series_labels), labels = unname(series_labels))
  )

# Plot absolute error
# Plot absolute error
# Plot absolute error
p_abs_week <- ggplot(week_abs_err, aes(x = week, y = abs_error, color = model, linetype = model)) +
  geom_hline(yintercept = 0, linewidth = 0.5) +
  geom_line(linewidth = 1) +
  labs(
    title = "Absolute error by week (|predicted rate − true rate|)",
    x = "Week",
    y = "Absolute error (percentage points)",
    color = "",
    linetype = ""
  ) +
  scale_y_continuous(labels = function(x) paste0(round(x * 100, 1), "%")) +
  theme_bw(base_family = "serif") +
  theme(
    panel.grid.major = element_line(linewidth = 0.35),
    panel.grid.minor = element_line(linewidth = 0.2),
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )

ggsave("./assignment3/figures/abs_error_by_week.pdf", p_abs_week, width = 10, height = 5.5, dpi = 300)
