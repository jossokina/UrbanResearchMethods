library(dplyr)
library(stargazer)
library(ggplot2)

# -----------------------------
# Load datasets
# -----------------------------
train <- read.csv("./assignment1/data/trainDataset.csv")
test  <- read.csv("./assignment1/data/testDataset.csv")

cat("✅ Loaded datasets\n")
cat("Train rows:", nrow(train), " cols:", ncol(train), "\n")
cat("Test  rows:", nrow(test),  " cols:", ncol(test),  "\n\n")

# -----------------------------
# Question 1: Visual analysis
# -----------------------------

# 1A) Scatter plot: speed_main vs flow_main
pdf("assignment1/figures/Q1_scatter_speed_vs_flow.pdf", width = 8, height = 6)
plot(
  train$flow_main,
  train$speed_main,
  xlab = "Traffic flow (flow_main, vehicles/hour)",
  ylab = "Traffic speed (speed_main, km/h)",
  main = "Scatter: Speed vs Flow (Train set)",
  pch = 19,
  col = rgb(0.2, 0.4, 0.6, 0.5)
)
dev.off()

# 1B) Box plot of speed_main
pdf("assignment1/figures/Q1_boxplot_speed.pdf", width = 8, height = 6)
boxplot(
  train$speed_main,
  ylab = "Traffic speed (speed_main, km/h)",
  main = "Boxplot of Traffic Speed (Train set)",
  col = rgb(0.2, 0.4, 0.6, 0.5)
)
dev.off()

# 1C) Histogram of speed_main
pdf("assignment1/figures/Q1_hist_speed.pdf", width = 8, height = 6)
hist(
  train$speed_main,
  breaks = 30,
  xlab = "Traffic speed (speed_main, km/h)",
  main = "Histogram of Traffic Speed (Train set)",
  col = rgb(0.2, 0.4, 0.6, 0.5),
  border = "white"
)
dev.off()

# 1D) Kernel density plot of speed_main
pdf("assignment1/figures/Q1_density_speed.pdf", width = 8, height = 6)
density_speed <- density(train$speed_main, na.rm = TRUE)
plot(
  density_speed,
  xlab = "Traffic speed (speed_main, km/h)",
  main = "Kernel Density of Traffic Speed (Train set)",
  col = "blue",
  lwd = 2
)
dev.off()


# Question 2 ----
### Correlations of speed with other variables.


# Make sure the output folder exists
dir.create("assignment1/tables", recursive = TRUE, showWarnings = FALSE)

# BOX C: Correlation ----
# IMPORTANT: correlation requires numeric columns only
train_dataset <- train %>% dplyr::select(where(is.numeric))

# Remove numeric columns with zero variance (constant columns)
#train_dataset <- train_dataset %>% dplyr::select(where(~ sd(.x, na.rm = TRUE) > 0))

target_col <- "speed_main"  # this is the target variable in the assignment

# Compute correlation of each predictor with speed_main
correlations <- sapply(train_dataset, function(x)
  cor(x, train_dataset[[target_col]], use = "complete.obs")
)

cor_matrix <- matrix(round(correlations, 3), ncol = 1)
rownames(cor_matrix) <- names(correlations)
colnames(cor_matrix) <- "Correlation"

# print the table (and save)
stargazer::stargazer(
  cor_matrix,
  type = "latex",
  title = "Correlation of Numeric Predictors with speed_main",
  digits = 3,
  summary = FALSE,
  rownames = TRUE,
  out = "assignment1/tables/correlations_vs_speed.latex"
)



# (Helpful print for the multiple-choice part)
# Tip from assignment: threshold = 0.6
good_predictors <- names(correlations)[abs(correlations) >= 0.6 & names(correlations) != target_col]

cat("\nVariables with |correlation| >= 0.6 (good predictors):\n")
print(good_predictors)

# Question 3 ----
### Data descriptives.
### Upload the image of the table with descriptives.
### Report: number non-missing observations, min, max, mean, st.dev.
### See R-Tips, Box B.

# Make sure folders exist
dir.create("assignment1/tables", recursive = TRUE, showWarnings = FALSE)

# BOX B: Descriptives in table ----
# (Keep only numeric columns, since descriptives are most meaningful for these)
train_dataset <- train %>% dplyr::select(where(is.numeric))

# save descriptives
stargazer(
  train_dataset,
  type = "latex",
  summary = TRUE,
  digits = 3,
  title = "Descriptive Statistics of Training Dataset",
  rownames = TRUE,
  out = "assignment1/tables/descriptive_statistics.latex"
)

# just print
summary(train_dataset)

cat("\n✅ Saved: assignment1/tables/descriptive_statistics.latex\n")

# Extra helpful prints for the multiple-choice parts in Question 3 ----

# (A) Types of variables (what is int, what is num)
cat("\nData types (structure):\n")
str(train_dataset)

# (B) Which variables have missing values?
na_counts <- colSums(is.na(train_dataset))
vars_with_na <- names(na_counts[na_counts > 0])

cat("\nVariables with missing values (and how many):\n")
print(na_counts[na_counts > 0])

# Keep only rows with no missing values
# Box B says: drop_na(variable_with_na)
# Here we automatically drop NA rows for ALL variables that have NAs.
if (length(vars_with_na) > 0) {
  train_dataset <- train_dataset[complete.cases(train_dataset[, vars_with_na, drop = FALSE]), ]
  cat("\n✅ Dropped rows with missing values in:\n")
  print(vars_with_na)
} else {
  cat("\n✅ No missing values found. No rows dropped.\n")
}

# Question 4 ----
### Linear model estimation.
### Estimate a linear model using all available data and all variables.
### Upload screenshot of output summary.
### See R-Tips, Box D.

# BOX D: Build Linear Model ----
# Make sure speed_main is included in train_dataset
# (If you created train_dataset in Question 3 as numeric columns, speed_main should be there.)

lm_model <- lm(speed_main ~ ., data = train_dataset)
# the dot . means "take all predictors"

# print output model
summary(lm_model)

# save output summary (latex table)
stargazer::stargazer(
  lm_model,
  type = "latex",
  summary = FALSE,
  digits = 3,
  title = "Full Model OLS",
  rownames = TRUE,
  out = "assignment1/tables/full_model_summary.latex"
)

cat("✅ Saved: assignment1/tables/full_model_summary.latex\n")

# Helpful: which variables did NOT get coefficients? (due to multicollinearity)
missing_coef <- names(coef(lm_model))[is.na(coef(lm_model))]
cat("\nVariables with NO estimated coefficient (NA):\n")
print(missing_coef)


# Question 5 (part 14) ----
### Residual analysis: plot residuals against fitted values.
### See R-Tips, Box E.

# extract residuals and fitted values
residuals_model <- residuals(lm_model)
fitted_values   <- fitted(lm_model)

# save plot as PDF
pdf("assignment1/figures/Q5_residuals_vs_fitted.pdf", width = 8, height = 6)

# plot residuals vs fitted values
plot(
  fitted_values,
  residuals_model,
  xlab = "Fitted values ",
  ylab = "Residuals ",
  main = "Residuals vs Fitted Values ",
  pch = 19,
  col = rgb(0.2, 0.4, 0.6, 0.5)
)

# add reference line at zero
abline(h = 0, col = "red")

dev.off()

cat("✅ Saved: assignment1/figures/Q5_residuals_vs_fitted.pdf\n")


# Question 5 (part 15-17) ----
### Improving your model: remove multicollinearity using correlations.
### See R-Tips, Box C (correlations) and Box D (linear model).



# -----------------------------------------------------
# Step 1: Study correlations between PREDICTORS (Box C)
# -----------------------------------------------------
# We work with numeric data; make sure speed_main is present
# and keep a separate object with predictors only.
predictors_only <- train_dataset %>% dplyr::select(-speed_main)

# ----- 1A) Which variables have high correlation (>0.6) with flow_main? -----
target_col <- "flow_main"

correlations_flow <- sapply(predictors_only, function(x)
  cor(x, predictors_only[[target_col]], use = "complete.obs")
)

cor_matrix_flow <- matrix(round(correlations_flow, 3), ncol = 1)
rownames(cor_matrix_flow) <- names(correlations_flow)
colnames(cor_matrix_flow) <- "Correlation"

stargazer::stargazer(
  cor_matrix_flow,
  type = "latex",
  title = "Correlation of Predictors with flow_main",
  digits = 3,
  summary = FALSE,
  rownames = TRUE,
  out = "assignment1/tables/correlations_vs_flow_main.latex"
)

cat("✅ Saved: assignment1/tables/correlations_vs_flow_main.latex\n")

# Variables to remove: abs(corr) > 0.6, excluding flow_main itself
high_corr_with_flow <- names(correlations_flow)[abs(correlations_flow) > 0.6 & names(correlations_flow) != target_col]

cat("\nVariables with |correlation| > 0.6 with flow_main (remove these):\n")
print(high_corr_with_flow)

# Remove them
new_dataset <- predictors_only[, !(names(predictors_only) %in% high_corr_with_flow)]
cat("\n✅ Removed variables highly correlated with flow_main.\n")

# ----- 1B) Which variables have high correlation (>0.6) with speed_ngh_432? -----
# Make sure you KEEP speed_ngh_432 itself.
target_col2 <- "speed_ngh_432"

# (If your dataset does not contain speed_ngh_432, this will error.
# In that case, check the variable name in names(new_dataset).)

correlations_speedngh <- sapply(new_dataset, function(x)
  cor(x, new_dataset[[target_col2]], use = "complete.obs")
)

cor_matrix_speedngh <- matrix(round(correlations_speedngh, 3), ncol = 1)
rownames(cor_matrix_speedngh) <- names(correlations_speedngh)
colnames(cor_matrix_speedngh) <- "Correlation"

stargazer::stargazer(
  cor_matrix_speedngh,
  type = "latex",
  title = "Correlation of Predictors with speed_ngh_432",
  digits = 3,
  summary = FALSE,
  rownames = TRUE,
  out = "assignment1/tables/correlations_vs_speed_ngh_432.latex"
)

cat("✅ Saved: assignment1/tables/correlations_vs_speed_ngh_432.latex\n")

# Variables to remove: abs(corr) > 0.6, excluding speed_ngh_432 itself
high_corr_with_speedngh <- names(correlations_speedngh)[abs(correlations_speedngh) > 0.6 & names(correlations_speedngh) != target_col2]

cat("\nVariables with |correlation| > 0.6 with speed_ngh_432 (remove these, keep speed_ngh_432):\n")
print(high_corr_with_speedngh)

# Remove them (but keep speed_ngh_432)
new_dataset2 <- new_dataset[, !(names(new_dataset) %in% high_corr_with_speedngh)]
cat("\n✅ Removed variables highly correlated with speed_ngh_432 (kept speed_ngh_432).\n")

# ----- 1C) Make the correlation matrix again (predictors only) -----
cor_pred <- cor(new_dataset2, use = "complete.obs")
cor_pred <- round(cor_pred, 3)


cor_pred_with_target <- cor(
  cbind(speed_main = train_dataset$speed_main, new_dataset2),
  use = "complete.obs"
)

cor_pred_with_target <- round(cor_pred_with_target, 3)

stargazer::stargazer(
  cor_pred_with_target,
  type = "latex",
  title = "Correlation Matrix (After Removing Collinear Predictors) INCLUDING speed_main",
  digits = 3,
  summary = FALSE,
  rownames = TRUE,
  out = "assignment1/tables/correlation_matrix_after_removals.latex"
)



# -----------------------------------------------------
# Step 2: Remove reference categories year2010 and hour6
# -----------------------------------------------------
# (Remove them if they exist)
vars_to_remove_refs <- c("")
vars_to_remove_refs <- vars_to_remove_refs[vars_to_remove_refs %in% names(new_dataset2)]

new_dataset3 <- new_dataset2[, !(names(new_dataset2) %in% vars_to_remove_refs)]
cat("\n✅ Removed reference categories (if present):\n")
print(vars_to_remove_refs)

# Report variables left
cat("\nVariables left in the data (predictors):\n")
print(names(new_dataset3))

# -----------------------------------------------------
# Step 3: Run linear model again (Box D), compute 1000-car effect
# -----------------------------------------------------
# Build final dataset with target + cleaned predictors
final_train_dataset <- cbind(speed_main = train_dataset$speed_main, new_dataset3)

lm_final <- lm(speed_main ~ ., data = final_train_dataset)

# print output model
summary(lm_final)

# save output summary
stargazer::stargazer(
  lm_final,
  type = "latex",
  summary = FALSE,
  digits = 3,
  title = "Final Model OLS (After Removing Collinearity + Reference Categories)",
  rownames = TRUE,
  out = "assignment1/tables/final_model_summary.latex"
)

cat("✅ Saved: assignment1/tables/final_model_summary.latex\n")

# Effect of 1000 additional cars on speed_main
beta_flow <- coef(lm_final)["flow_main"]
effect_1000 <- beta_flow * 1000

cat("\nEffect of 1000 additional cars (flow_main) on speed_main:\n")
print(effect_1000)

